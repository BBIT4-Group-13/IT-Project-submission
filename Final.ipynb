{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773b7ca4-4480-40c5-85d6-6b591cc546ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We hosted Top Academic Achievers of Mwakirunge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Good 0 and motivational leadership is key...wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It is with deep sorrow that we announce the pa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Our 3rd Year statistics students toured Kenya ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Visit by the Kenya Space Weather team to launc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Department                                           Comments Unnamed: 2  \\\n",
       "0           0  We hosted Top Academic Achievers of Mwakirunge...        NaN   \n",
       "1           0  Good 0 and motivational leadership is key...wi...        NaN   \n",
       "2           0  It is with deep sorrow that we announce the pa...        NaN   \n",
       "3           1  Our 3rd Year statistics students toured Kenya ...        NaN   \n",
       "4           0  Visit by the Kenya Space Weather team to launc...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7  Unnamed: 8  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "1        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "2        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "3        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "4        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "\n",
       "   Unnamed: 9  Unnamed: 10  Unnamed: 11  Unnamed: 12  Unnamed: 13  \\\n",
       "0         NaN          NaN          NaN          NaN          NaN   \n",
       "1         NaN          NaN          NaN          NaN          NaN   \n",
       "2         NaN          NaN          NaN          NaN          NaN   \n",
       "3         NaN          NaN          NaN          NaN          NaN   \n",
       "4         NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 14  Unnamed: 15  Unnamed: 16 Unnamed: 17  \n",
       "0          NaN          NaN          NaN         NaN  \n",
       "1          NaN          NaN          NaN         NaN  \n",
       "2          NaN          NaN          NaN         NaN  \n",
       "3          NaN          NaN          NaN         NaN  \n",
       "4          NaN          NaN          NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\san\\Documents\\Data\\Numbers.csv\" , encoding = \"ISO-8859-1\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75371d44-6783-452b-8465-70bb9e1c85bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Department                                           Comments Unnamed: 2  \\\n",
       "0             0  We hosted Top Academic Achievers of Mwakirunge...        NaN   \n",
       "1             0  Good 0 and motivational leadership is key...wi...        NaN   \n",
       "2             0  It is with deep sorrow that we announce the pa...        NaN   \n",
       "3             1  Our 3rd Year statistics students toured Kenya ...        NaN   \n",
       "4             0  Visit by the Kenya Space Weather team to launc...        NaN   \n",
       "..          ...                                                ...        ...   \n",
       "184           5  We will help you explain the short roles on yo...        NaN   \n",
       "185           1  To the math and computer science courses. Some...        NaN   \n",
       "186           3  Remember to always carry your school ID with y...        NaN   \n",
       "187           1  To sum it all the advice remained that student...        NaN   \n",
       "188           1  Exams irregularities is one the pandemic that ...        NaN   \n",
       "\n",
       "    Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7  Unnamed: 8  \\\n",
       "0          NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "1          NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "2          NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "3          NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "4          NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "..         ...        ...        ...        ...        ...         ...   \n",
       "184        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "185        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "186        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "187        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "188        NaN        NaN        NaN        NaN        NaN         NaN   \n",
       "\n",
       "     Unnamed: 9  Unnamed: 10  Unnamed: 11  Unnamed: 12  Unnamed: 13  \\\n",
       "0           NaN          NaN          NaN          NaN          NaN   \n",
       "1           NaN          NaN          NaN          NaN          NaN   \n",
       "2           NaN          NaN          NaN          NaN          NaN   \n",
       "3           NaN          NaN          NaN          NaN          NaN   \n",
       "4           NaN          NaN          NaN          NaN          NaN   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "184         NaN          NaN          NaN          NaN          NaN   \n",
       "185         NaN          NaN          NaN          NaN          NaN   \n",
       "186         NaN          NaN          NaN          NaN          NaN   \n",
       "187         NaN          NaN          NaN          NaN          NaN   \n",
       "188         NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Unnamed: 14  Unnamed: 15  Unnamed: 16 Unnamed: 17  \n",
       "0            NaN          NaN          NaN         NaN  \n",
       "1            NaN          NaN          NaN         NaN  \n",
       "2            NaN          NaN          NaN         NaN  \n",
       "3            NaN          NaN          NaN         NaN  \n",
       "4            NaN          NaN          NaN         NaN  \n",
       "..           ...          ...          ...         ...  \n",
       "184          NaN          NaN          NaN         NaN  \n",
       "185          NaN          NaN          NaN         NaN  \n",
       "186          NaN          NaN          NaN         NaN  \n",
       "187          NaN          NaN          NaN         NaN  \n",
       "188          NaN          NaN          NaN         NaN  \n",
       "\n",
       "[189 rows x 18 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5633969b-b871-4cca-82c5-ee19a9e5efeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45\n",
       "1    42\n",
       "3    40\n",
       "5    27\n",
       "6    17\n",
       "2    12\n",
       "4     6\n",
       "Name: Department, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Department'] = df['Department'].astype(int)\n",
    "df['Department'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a7b8c1-224a-4c05-aff4-9df287e5cd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab72b0b38ed429e990697a52f37559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "token = tokenizer.encode_plus(\n",
    "    df['Comments'].iloc[0], \n",
    "    max_length=256, \n",
    "    truncation=True, \n",
    "    padding='max_length', \n",
    "    add_special_tokens=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "token.input_ids\n",
    "X_input_ids = np.zeros((len(df), 256))\n",
    "X_attn_masks = np.zeros((len(df), 256))\n",
    "\n",
    "def generate_training_data(df, ids, masks, tokenizer):\n",
    "    for i, text in tqdm(enumerate(df['Comments'])):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=256, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            add_special_tokens=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        ids[i, :] = tokenized_text.input_ids\n",
    "        masks[i, :] = tokenized_text.attention_mask\n",
    "    return ids, masks\n",
    "\n",
    "X_input_ids, X_attn_masks = generate_training_data(df, X_input_ids, X_attn_masks, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fe9387-755b-4b46-ad5d-820bca5987f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((len(df), 7))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49bc9bde-c673-4849-b691-f3f07bae6084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[np.arange(len(df)), df['Department'].values] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37e7fa3-a3ee-4816-836c-3321e2a96e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(256,), dtype=tf.float64, name=None), TensorSpec(shape=(7,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7dded4-883c-43dc-8b84-1f3552786a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(256,), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(256,), dtype=tf.float64, name=None)}, TensorSpec(shape=(7,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }, labels\n",
    "\n",
    "dataset = dataset.map(SentimentDatasetMapFunction)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "344d30a8-da6e-4501-9703-3d38d15600b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(16, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae3f717-297d-43c1-91bf-a8ab6d2f9400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 256), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(16, 256), dtype=tf.float64, name=None)}, TensorSpec(shape=(16, 7), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59592f80-5d99-4e88-bb8b-1cd934d4b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.8\n",
    "train_size = int((len(df)//16)*p)\n",
    "\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb85ee51-046e-434c-a678-24022bbe04d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "from transformers import TFBertModel\n",
    "\n",
    "model = TFBertModel.from_pretrained('bert-base-cased') # bert base model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe6e13a-a7e4-4d3e-aa7d-2eef0d4b627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " intermediate_layer (Dense)     (None, 512)          393728      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 7)            3591        ['intermediate_layer[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,707,591\n",
      "Trainable params: 108,707,591\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "\n",
    "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] # 0 -> activation layer (3D), 1 -> pooled output layer (2D)\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "output_layer = tf.keras.layers.Dense(7, activation='softmax', name='output_layer')(intermediate_layer) # softmax -> calcs probs of classes\n",
    "\n",
    "sentiment_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80d3e091-4bfc-4618-8753-7716f721f7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "8/8 [==============================] - 1439s 181s/step - loss: 1.3064 - accuracy: 0.5938 - val_loss: 1.2154 - val_accuracy: 0.7500\n",
      "Epoch 2/8\n",
      "8/8 [==============================] - 860s 102s/step - loss: 1.1797 - accuracy: 0.7109 - val_loss: 1.0732 - val_accuracy: 0.7083\n",
      "Epoch 3/8\n",
      "8/8 [==============================] - 762s 98s/step - loss: 1.0294 - accuracy: 0.7500 - val_loss: 0.9447 - val_accuracy: 0.7708\n",
      "Epoch 4/8\n",
      "8/8 [==============================] - 1211s 163s/step - loss: 0.9804 - accuracy: 0.7109 - val_loss: 0.8489 - val_accuracy: 0.7292\n",
      "Epoch 5/8\n",
      "8/8 [==============================] - 683s 84s/step - loss: 0.8912 - accuracy: 0.7578 - val_loss: 0.6744 - val_accuracy: 0.8542\n",
      "Epoch 6/8\n",
      "8/8 [==============================] - 1012s 133s/step - loss: 0.7737 - accuracy: 0.8047 - val_loss: 0.5973 - val_accuracy: 0.8542\n",
      "Epoch 7/8\n",
      "8/8 [==============================] - 1079s 138s/step - loss: 0.6669 - accuracy: 0.8281 - val_loss: 0.5570 - val_accuracy: 0.8750\n",
      "Epoch 8/8\n",
      "8/8 [==============================] - 1212s 157s/step - loss: 0.5754 - accuracy: 0.8516 - val_loss: 0.4986 - val_accuracy: 0.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TTu_model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TTu_model1\\assets\n"
     ]
    }
   ],
   "source": [
    "optim = tf.keras.optimizers.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "sentiment_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])\n",
    "hist = sentiment_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=8\n",
    ")\n",
    "\n",
    "\n",
    "sentiment_model.save('TTu_model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a70d745-ca45-48c2-b336-7fe719b19ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter comment here:  Greetings from Taita Taveta University; The University Bus will be available at Voi town to feryy First year Students and Parents free of charge on Monday (20/09/2021) from 6am. For those who will be arriving with the SGR at 12noon the University Bus will be picking you up at the SGR Voi station. Welcome to Taita Taveta University; Home of Ideas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Administration\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = tf.keras.models.load_model('TTu_model1')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=256, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "    }\n",
    "\n",
    "def make_prediction(model, processed_data, classes=['Administration', 'Academics', 'Elections', 'Health', 'Extra-curricular' , 'Spam', 'Sports']):\n",
    "    probs = model.predict(processed_data)[0]\n",
    "    return classes[np.argmax(probs)]\n",
    "\n",
    "\n",
    "input_text = input('Enter comment here: ')\n",
    "processed_data = prepare_data(input_text, tokenizer)\n",
    "result = make_prediction(sentiment_model, processed_data=processed_data)\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ade5df-a054-4495-9d4e-1859cdb96662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
